"use strict";(self.webpackChunkredkubes_github_io=self.webpackChunkredkubes_github_io||[]).push([[7314],{8868:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>i,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"for-ops/disaster-recovery/platform-databases","title":"Restoring platform databases","description":"Generally it is recommended to get familiar with the CNPG documentation on how to restore a PostgreSQL database. The steps here are written down specifically for App Platform for LKE.","source":"@site/docs/for-ops/disaster-recovery/platform-databases.md","sourceDirName":"for-ops/disaster-recovery","slug":"/for-ops/disaster-recovery/databases","permalink":"/docs/for-ops/disaster-recovery/databases","draft":false,"unlisted":false,"editUrl":"https://github.com/linode/linode.github.io/tree/main/docs/for-ops/disaster-recovery/platform-databases.md","tags":[],"version":"current","frontMatter":{"slug":"databases","title":"Restoring platform databases","sidebar_label":"Databases"},"sidebar":"mainSidebar","previous":{"title":"Gitea","permalink":"/docs/for-ops/disaster-recovery/gitea"},"next":{"title":"Reinstall","permalink":"/docs/for-ops/disaster-recovery/reinstall"}}');var s=n(4848),r=n(8453);const o={slug:"databases",title:"Restoring platform databases",sidebar_label:"Databases"},c=void 0,i={},l=[{value:"Initial notes",id:"initial-notes",level:2},{value:"Regular recovery with backup in same cluster",id:"regular-recovery-with-backup-in-same-cluster",level:2},{value:"Listing backup resources",id:"listing-backup-resources",level:3},{value:"Adjustments to the backup configuration",id:"adjustments-to-the-backup-configuration",level:3},{value:"Adjustments to the database configuration",id:"adjustments-to-the-database-configuration",level:3},{value:"Shutting down services",id:"shutting-down-services",level:3},{value:"Removing the existing database",id:"removing-the-existing-database",level:3},{value:"Restarting services",id:"restarting-services",level:3},{value:"Obtaining a backup outside the cluster",id:"obtaining-a-backup-outside-the-cluster",level:2},{value:"Point-in-time recovery",id:"point-in-time-recovery",level:2},{value:"Emergency backup and restore",id:"emergency-backup-and-restore",level:2},{value:"Gitea database",id:"gitea-database",level:3},{value:"Keycloak database",id:"keycloak-database",level:3},{value:"Harbor database",id:"harbor-database",level:3}];function d(e){const a={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(a.p,{children:["Generally it is recommended to get familiar with the ",(0,s.jsx)(a.a,{href:"https://cloudnative-pg.io/documentation/current/recovery/",children:"CNPG documentation"})," on how to restore a PostgreSQL database. The steps here are written down specifically for App Platform for LKE."]}),"\n",(0,s.jsx)(a.h2,{id:"initial-notes",children:"Initial notes"}),"\n",(0,s.jsx)(a.p,{children:"Since the procedure requires patching the existing Kubernetes resources, the apl-operator must be scaled down to prevent overwrites:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{children:'kubectl patch application -n argocd apl-operator-apl-operator --patch \'[{"op": "remove", "path": "/spec/syncPolicy/automated"}]\' --type=json\nkubectl scale --replicas=0 -n apl-operator deployment apl-operator\n'})}),"\n",(0,s.jsx)(a.p,{children:"Once the restore procedure is completed, enable the apl-operator:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{children:"kubectl scale --replicas=1 -n apl-operator deployment apl-operator\n"})}),"\n",(0,s.jsxs)(a.p,{children:["Changes to the ",(0,s.jsx)(a.code,{children:"values"})," repository can usually be made through the Gitea UI after signing in with the ",(0,s.jsx)(a.code,{children:"platform-admin"})," user. As this requires Keycloak in addition to Gitea operating normally, the risk can be reduced by creating an application token and pulling/pushing local changes to the repository. In Gitea, go to the user settings, click on the ",(0,s.jsx)(a.code,{children:"Applications"})," tab, enter a token name and select ",(0,s.jsx)(a.code,{children:"repo"})," as the scope. After creating this token, you can include it in the repository URL, e.g."]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"git clone https://<token>@gitea.example.com/otomi/values.git\n"})}),"\n",(0,s.jsxs)(a.p,{children:["In the event that platform-critical services Gitea and Keycloak are not able to start, required changes to the database configuration can be applied directly in the following Argo CD applications in the ",(0,s.jsx)(a.code,{children:"argocd"})," namespace:"]}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:["Gitea database: ",(0,s.jsx)(a.code,{children:"gitea-gitea-otomi-db"})]}),"\n",(0,s.jsxs)(a.li,{children:["Keycloak database: ",(0,s.jsx)(a.code,{children:"keycloak-keycloak-otomi-db"})]}),"\n"]}),"\n",(0,s.jsxs)(a.p,{children:["Where applicable, in these manifests the ",(0,s.jsx)(a.code,{children:"initdb"})," section in ",(0,s.jsx)(a.code,{children:"clusterSpec.bootstrap"})," can be replaced with ",(0,s.jsx)(a.code,{children:"recovery"})," and ",(0,s.jsx)(a.code,{children:"externalClusters"})," just as instructed below. Note that ",(0,s.jsx)(a.code,{children:"recovery"})," and ",(0,s.jsx)(a.code,{children:"externalClusters"})," do not need to be reflected in the values file later, since they are only considered when initializing the cluster."]}),"\n",(0,s.jsx)(a.h2,{id:"regular-recovery-with-backup-in-same-cluster",children:"Regular recovery with backup in same cluster"}),"\n",(0,s.jsx)(a.p,{children:"This procedure should be taken if the database has gotten to an unhealthy state, e.g. because of volume filesystem corruption. For reverting undesired updates, additional instructions for a point-in-time recovery are to be considered as described in the following sections."}),"\n",(0,s.jsx)(a.p,{children:"Recovering any of the platform databases should be performed in the following order:"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:["Note the name of the ",(0,s.jsx)(a.code,{children:"Backup"})," resource that you intend to run the recovery from."]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:"Make adjustments to the values as described in this section. This needs to be done within the values repository directly, since this is not exposed to the platform API."}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:"Shut down the service accessing the database (see above)."}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:["Halt ArgoCD auto-sync and delete the database ",(0,s.jsx)(a.code,{children:"Cluster"})," resource."]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:"Re-enable ArgoCD sync."}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:"Re-enable the backup disabled in step 2. This is also possible via the Console."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"listing-backup-resources",children:"Listing backup resources"}),"\n",(0,s.jsxs)(a.p,{children:["Available backups can be listed using the following command. Consider only ",(0,s.jsx)(a.code,{children:"completed"})," ones for recovery.\nNote that the time stamps of the backup names are universal time (UTC)."]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl get backup -n <app>\n"})}),"\n",(0,s.jsxs)(a.p,{children:["where ",(0,s.jsx)(a.code,{children:"<app>"})," is to be replaced with ",(0,s.jsx)(a.code,{children:"gitea"}),", ",(0,s.jsx)(a.code,{children:"harbor"}),", or ",(0,s.jsx)(a.code,{children:"keycloak"}),"."]}),"\n",(0,s.jsx)(a.h3,{id:"adjustments-to-the-backup-configuration",children:"Adjustments to the backup configuration"}),"\n",(0,s.jsx)(a.p,{children:"After the recovery, new backups will be created. For avoiding accidental mixing and overwriting of backups, CloudnativePG does not allow for the new backup and the recovery source to be in the same location. Therefore, the backups should be temporarily disabled, and the suffix (the directory inside the object storage) are to be adjusted."}),"\n",(0,s.jsxs)(a.p,{children:["Inside ",(0,s.jsx)(a.code,{children:"env/settings.yaml"}),", locate the path ",(0,s.jsx)(a.code,{children:"platformBackups.database.<app>"})," (where ",(0,s.jsx)(a.code,{children:"<app>"})," is either ",(0,s.jsx)(a.code,{children:"gitea"}),", ",(0,s.jsx)(a.code,{children:"harbor"}),", or ",(0,s.jsx)(a.code,{children:"keycloak"}),") and set the values ",(0,s.jsx)(a.code,{children:"enabled: false"})," and ",(0,s.jsx)(a.code,{children:"pathSuffix: <app>-1"}),". The path suffix may also be set to something completely different, but must not exist in the object storage."]}),"\n",(0,s.jsx)(a.p,{children:"Example:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"# ...\nplatformBackups:\n  database:\n    gitea:\n      enabled: false\n      retentionPolicy: 7d\n      schedule: 0 0 * * *\n      pathSuffix: gitea-1\n# ...\n"})}),"\n",(0,s.jsx)(a.h3,{id:"adjustments-to-the-database-configuration",children:"Adjustments to the database configuration"}),"\n",(0,s.jsx)(a.p,{children:"The following change only has an effect on an initial database cluster. Therefore it can be made ahead of shutting down platform-critical services."}),"\n",(0,s.jsxs)(a.p,{children:["In the file ",(0,s.jsx)(a.code,{children:"env/databases/<app>.yaml"}),", update the structure of ",(0,s.jsx)(a.code,{children:"databases.<app>.recovery"})," as follows, depending on the app, inserting the backup name as determined above:"]}),"\n",(0,s.jsx)(a.p,{children:"For Gitea:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"databases:\n  gitea:\n    # ...\n    recovery:\n      backup:\n        name: <backup-name>\n      database: gitea\n      owner: gitea\n      secret:\n        name: gitea-db-secret\n"})}),"\n",(0,s.jsx)(a.p,{children:"For Harbor:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"databases:\n  harbor:\n    # ...\n    recovery:\n      backup:\n        name: <backup-name>\n      database: registry\n      owner: harbor\n"})}),"\n",(0,s.jsx)(a.p,{children:"For Keycloak:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"databases:\n  keycloak:\n    # ...\n    recovery:\n      backup:\n        name: <backup-name>\n      database: keycloak\n      owner: keycloak\n"})}),"\n",(0,s.jsxs)(a.p,{children:["Note that ArgoCD may show a sync error, pointing out that there are multiple ",(0,s.jsx)(a.code,{children:"bootstrap"})," configurations on an existing database cluster. This will be resolved in the following steps."]}),"\n",(0,s.jsx)(a.h3,{id:"shutting-down-services",children:"Shutting down services"}),"\n",(0,s.jsx)(a.p,{children:"Check the Tekton pipelines to ensure that values changes have been deployed as expected. After this, during a backup or recovery of the database, the application should to be shut down for avoiding any write operations leading to inconsistencies."}),"\n",(0,s.jsx)(a.p,{children:"For temporarily disabling Gitea:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Disable ArgoCD auto-sync during the changes\nkubectl patch application -n argocd gitea-gitea --patch \'[{"op": "remove", "path": "/spec/syncPolicy/automated"}]\' --type=json\n## Scale Gitea deployment to zero\nkubectl scale deployment -n gitea gitea --replicas=0\n## Verify that pods are shut down\nkubectl get deployment -n gitea gitea  # Should show READY 0/0\n'})}),"\n",(0,s.jsx)(a.p,{children:"For temporarily disabling Keycloak:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Disable ArgoCD auto-sync during the changes\nkubectl patch application -n argocd keycloak-keycloak-operator --patch \'[{"op": "remove", "path": "/spec/syncPolicy/automated"}]\' --type=json\n## Scale Keycloak statefulset to zero\nkubectl  scale statefulset -n keycloak keycloak --replicas=0\n## Verify that pods are shut down\nkubectl get statefulset -n keycloak keycloak  # Should show READY 0/0\n'})}),"\n",(0,s.jsx)(a.p,{children:"For temporarily disabling Harbor:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Disable ArgoCD auto-sync during the changes\nkubectl patch application -n argocd harbor-harbor --patch \'[{"op": "remove", "path": "/spec/syncPolicy/automated"}]\' --type=json\n## Scale Harbor deployment to zero\nkubectl scale deployment -n harbor harbor-core --replicas=0\n## Verify that pods are shut down\nkubectl get deploy -n harbor harbor-core  # Should show READY 0/0\n'})}),"\n",(0,s.jsx)(a.h3,{id:"removing-the-existing-database",children:"Removing the existing database"}),"\n",(0,s.jsx)(a.p,{children:"After deploying the values changes and shutting down applications accessing the database, delete the database cluster."}),"\n",(0,s.jsx)(a.p,{children:"For Gitea:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Disable ArgoCD auto-sync during the changes\nkubectl patch application -n argocd gitea-gitea-otomi-db --patch \'[{"op": "remove", "path": "/spec/syncPolicy/automated"}]\' --type=json\n## Delete the cluster\nkubectl delete cluster -n gitea gitea-db\n## Re-enable ArgoCD auto-sync\nkubectl patch application -n argocd gitea-gitea-otomi-db --patch \'[{"op": "add", "path": "/spec/syncPolicy/automated", "value": {"prune": true, "allowEmpty": true}}]\' --type=json\n'})}),"\n",(0,s.jsx)(a.p,{children:"For Harbor:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Disable ArgoCD auto-sync during the changes\nkubectl patch application -n argocd harbor-harbor-otomi-db --patch \'[{"op": "remove", "path": "/spec/syncPolicy/automated"}]\' --type=json\n## Delete the cluster\nkubectl delete cluster -n harbor harbor-otomi-db\n## Re-enable ArgoCD auto-sync\nkubectl patch application -n argocd harbor-harbor-otomi-db --patch \'[{"op": "add", "path": "/spec/syncPolicy/automated", "value": {"prune": true, "allowEmpty": true}}]\' --type=json\n'})}),"\n",(0,s.jsx)(a.p,{children:"For Keycloak:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Disable ArgoCD auto-sync during the changes\nkubectl patch application -n argocd keycloak-keycloak-otomi-db --patch \'[{"op": "remove", "path": "/spec/syncPolicy/automated"}]\' --type=json\n## Delete the cluster\nkubectl delete cluster -n keycloak keycloak-db\n## Re-enable ArgoCD auto-sync\nkubectl patch application -n argocd keycloak-keycloak-otomi-db --patch \'[{"op": "add", "path": "/spec/syncPolicy/automated", "value": {"prune": true, "allowEmpty": true}}]\' --type=json\n'})}),"\n",(0,s.jsxs)(a.p,{children:["The cluster should now be recreated from the backup. Wait until the ",(0,s.jsx)(a.code,{children:"Cluster"})," status shows ",(0,s.jsx)(a.code,{children:"Cluster in healthy state"})," and restart the dependent services."]}),"\n",(0,s.jsx)(a.h3,{id:"restarting-services",children:"Restarting services"}),"\n",(0,s.jsx)(a.p,{children:"For restoring Gitea processes:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Re-enable ArgoCD auto-sync, which should also change the Gitea statefulset to scale up\nkubectl patch application -n argocd gitea-gitea --patch \'[{"op": "add", "path": "/spec/syncPolicy/automated", "value": {"prune": true, "allowEmpty": true}}]\' --type=json\n## Optional: scale up, for not having to wait for re-sync of ArgoCD\nkubectl patch statefulset -n gitea gitea --patch \'[{"op": "replace", "path": "/spec/replicas", "value": 1}]\' --type=json\n'})}),"\n",(0,s.jsx)(a.p,{children:"For restoring Keycloak processes:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Re-enable ArgoCD auto-sync\nkubectl patch application -n argocd keycloak-keycloak-operator-cr --patch \'[{"op": "add", "path": "/spec/syncPolicy/automated", "value": {"prune": true, "allowEmpty": true}}]\' --type=json\n## Optional: scale up, for not having to wait for re-sync of ArgoCD\nkubectl patch keycloak -n keycloak keycloak --patch \'[{"op": "replace", "path": "/spec/instances", "value": 1}]\' --type=json\n## Required: force a restart of the platform Keycloak operator; ArgoCD re-creates the Deployment\nkubectl delete deploy -n apl-keycloak-operator apl-keycloak-operator\n'})}),"\n",(0,s.jsx)(a.p,{children:"For restoring Harbor processes:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:'## Re-enable ArgoCD auto-sync\nkubectl patch application -n argocd harbor-harbor --patch \'[{"op": "add", "path": "/spec/syncPolicy/automated", "value": {"prune": true, "allowEmpty": true}}]\' --type=json\n## Optional: scale up, for not having to wait for re-sync of ArgoCD\nkubectl patch deploy -n harbor harbor-core --patch \'[{"op": "replace", "path": "/spec/replicas", "value": 1}]\' --type=json\n'})}),"\n",(0,s.jsx)(a.h2,{id:"obtaining-a-backup-outside-the-cluster",children:"Obtaining a backup outside the cluster"}),"\n",(0,s.jsxs)(a.p,{children:["The following instructions for example apply for Gitea in the last step of ",(0,s.jsx)(a.a,{href:"/docs/for-ops/disaster-recovery/reinstall",children:"reinstalling a platform setup on a new cluster"}),". If the backup to recover from is not available as a ",(0,s.jsx)(a.code,{children:"Backup"})," resource within the cluster, but in an attached object storage, follow the instructions above, except for making the following change to ",(0,s.jsx)(a.code,{children:"env/databases/<app>.yaml"})," in the ",(0,s.jsx)(a.code,{children:"values"})," repository:"]}),"\n",(0,s.jsxs)(a.p,{children:["Adjust the object storage parameters below as needed, at least replacing the ",(0,s.jsx)(a.code,{children:"<bucket-name>"})," and ",(0,s.jsx)(a.code,{children:"<location>"})," placeholders. Typically ",(0,s.jsx)(a.code,{children:"serverName"})," should remain unchanged. ",(0,s.jsx)(a.code,{children:"linode-creds"})," are the account credentials set up by the platform and can be reused provided that they have access to the storage."]}),"\n",(0,s.jsx)(a.p,{children:"env/databases/gitea.yaml:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"databases:\n  gitea:\n    # ...\n    recovery:\n      source: gitea-backup\n      database: gitea\n      owner: gitea\n    externalClusters:\n      - name: gitea-backup\n        barmanObjectStore:\n          serverName: gitea-db\n          destinationPath: s3://<bucket-name>/gitea\n          endpointURL: https://<location>.linodeobjects.com\n          s3Credentials:\n            accessKeyId:\n              name: linode-creds\n              key: S3_STORAGE_ACCOUNT\n            secretAccessKey:\n              name: linode-creds\n              key: S3_STORAGE_KEY\n          wal:\n            compression: gzip\n            maxParallel: 8\n          data:\n            compression: gzip\n"})}),"\n",(0,s.jsx)(a.p,{children:"env/databases/harbor.yaml:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"databases:\n  harbor:\n    # ...\n    recovery:\n      source: harbor-backup\n      database: registry\n      owner: harbor\n    externalClusters:\n      - name: harbor-backup\n        barmanObjectStore:\n          serverName: harbor-otomi-db\n          destinationPath: s3://<bucket-name>/harbor\n          endpointURL: https://<location>.linodeobjects.com\n          s3Credentials:\n            accessKeyId:\n              name: linode-creds\n              key: S3_STORAGE_ACCOUNT\n            secretAccessKey:\n              name: linode-creds\n              key: S3_STORAGE_KEY\n          wal:\n            compression: gzip\n            maxParallel: 8\n          data:\n            compression: gzip\n"})}),"\n",(0,s.jsx)(a.p,{children:"env/databases/keycloak.yaml:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"databases:\n  keycloak:\n    # ...\n    recovery:\n      source: keycloak-backup\n      database: keycloak\n      owner: keycloak\n    externalClusters:\n      - name: keycloak-backup\n        barmanObjectStore:\n          serverName: keycloak-db\n          destinationPath: s3://<bucket-name>/keycloak\n          endpointURL: https://<location>.linodeobjects.com\n          s3Credentials:\n            accessKeyId:\n              name: linode-creds\n              key: S3_STORAGE_ACCOUNT\n            secretAccessKey:\n              name: linode-creds\n              key: S3_STORAGE_KEY\n          wal:\n            compression: gzip\n            maxParallel: 8\n          data:\n            compression: gzip\n"})}),"\n",(0,s.jsx)(a.h2,{id:"point-in-time-recovery",children:"Point-in-time recovery"}),"\n",(0,s.jsxs)(a.p,{children:["For restoring a backup only up to a specific point in time, add a recovery target to the ",(0,s.jsx)(a.code,{children:"recovery"})," sections above, according to the ",(0,s.jsx)(a.a,{href:"https://cloudnative-pg.io/documentation/current/recovery/#point-in-time-recovery-pitr",children:"CloudnativePG docs"}),". For example, for restoring Gitea up to a change that was made after 2023-03-06 08:00:39 CET, add the following value:"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"databases:\n  gitea:\n    # ...\n    recovery:\n      source: gitea-backup\n      database: gitea\n      owner: gitea\n      recoveryTarget:\n        # Time base target for the recovery\n        targetTime: '2023-03-06 08:00:39+01'\n    externalClusters:\n    # ...\n"})}),"\n",(0,s.jsxs)(a.p,{children:["You can also use a ",(0,s.jsx)(a.a,{href:"#regular-recovery-with-backup-in-same-cluster",children:"named backup resource"}),". However, the backup must be from ",(0,s.jsx)(a.strong,{children:"before"})," the timestamp you choose as a recovery target, considering that they are named with a timestamp in universal time (UTC)."]}),"\n",(0,s.jsxs)(a.p,{children:["Note that the timestamp above is not exactly in the common ISO 8601 format such as ",(0,s.jsx)(a.code,{children:"2023-07-06T08:00:39Z"}),". Instead date and time must be separated by space and the timezone should be written out explicitly such as ",(0,s.jsx)(a.code,{children:"+00"})," (for UTC) or ",(0,s.jsx)(a.code,{children:"+01"})," (for CET without DST). For all valid formats, refer to the ",(0,s.jsx)(a.a,{href:"https://www.postgresql.org/docs/current/datatype-datetime.html#DATATYPE-DATETIME-INPUT-TIME-STAMPS",children:"specific section of the PostgreSQL documentation"}),"."]}),"\n",(0,s.jsx)(a.h2,{id:"emergency-backup-and-restore",children:"Emergency backup and restore"}),"\n",(0,s.jsxs)(a.p,{children:["The methods using the built-in tools of PostgreSQL ",(0,s.jsx)(a.code,{children:"pg_dump"})," and ",(0,s.jsx)(a.code,{children:"pg_restore"})," should be used of the operator is not available. This type of backup can also be used as an additional safety measure before using any of the aforementioned methods. Be aware that the backups are stored on the computer where the commands are executed. This requires a stable connection to the database pods during the time of the backup and recovery."]}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:["Scale the application to zero that is using the database cluster (",(0,s.jsx)(a.a,{href:"#shutting-down-services",children:"see above"}),")."]}),"\n",(0,s.jsx)(a.li,{children:"Perform the backup or the restore as needed (following commands)."}),"\n",(0,s.jsxs)(a.li,{children:["Restore the application processes (",(0,s.jsx)(a.a,{href:"#restarting-services",children:"see above"}),")."]}),"\n"]}),"\n",(0,s.jsxs)(a.p,{children:["Note that in difference to the commands as documented in the ",(0,s.jsx)(a.a,{href:"https://cloudnative-pg.io/documentation/current/troubleshooting/#emergency-backup",children:"CNPG site"}),", the following ",(0,s.jsx)(a.code,{children:"pg_restore"})," commands include the ",(0,s.jsx)(a.code,{children:"--clean"})," flag which will clear tables before the import. Otherwise, the import will likely fail as the database is usually not empty after the application has been initializing it on startup. Nevertheless ",(0,s.jsx)(a.strong,{children:"use this flag with care"}),"!"]}),"\n",(0,s.jsxs)(a.p,{children:["In the following steps, the ",(0,s.jsx)(a.code,{children:"-n"})," suffix of each pod name (e.g. ",(0,s.jsx)(a.code,{children:"gitea-db-n"}),") needs to be replaced with the primary pod instance (e.g. ",(0,s.jsx)(a.code,{children:"kubectl exec -n gitea gitea-db-1 ..."}),")."]}),"\n",(0,s.jsx)(a.h3,{id:"gitea-database",children:"Gitea database"}),"\n",(0,s.jsx)(a.p,{children:"Determine the primary instance:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl get cluster -n gitea gitea-db\n"})}),"\n",(0,s.jsx)(a.p,{children:"Backup:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl exec -n gitea gitea-db-n postgres \\\n  -- pg_dump -Fc -d gitea > gitea.dump\n"})}),"\n",(0,s.jsx)(a.p,{children:"Restore:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl exec -i -n gitea gitea-db-n postgres \\\n  -- pg_restore --no-owner --role=gitea -d gitea --verbose --clean < gitea.dump\n"})}),"\n",(0,s.jsx)(a.h3,{id:"keycloak-database",children:"Keycloak database"}),"\n",(0,s.jsx)(a.p,{children:"Determine the primary instance:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl get cluster -n keycloak keycloak-db\n"})}),"\n",(0,s.jsx)(a.p,{children:"Backup:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl exec -n keycloak keycloak-db-n postgres \\\n  -- pg_dump -Fc -d keycloak > keycloak.dump\n"})}),"\n",(0,s.jsx)(a.p,{children:"Restore:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl exec -i -n keycloak keycloak-db-n postgres \\\n  -- pg_restore --no-owner --role=keycloak -d keycloak --verbose --clean < keycloak.dump\n"})}),"\n",(0,s.jsx)(a.h3,{id:"harbor-database",children:"Harbor database"}),"\n",(0,s.jsx)(a.p,{children:"Determine the primary instance:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl get cluster -n harbor harbor-otomi-db\n"})}),"\n",(0,s.jsx)(a.p,{children:"Backup:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl exec -n harbor harbor-otomi-db-n postgres \\\n  -- pg_dump -Fc -d harbor > harbor.dump\n"})}),"\n",(0,s.jsx)(a.p,{children:"Restore:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-sh",children:"kubectl exec -i -n harbor harbor-otomi-db-n postgres \\\n  -- pg_restore --no-owner --role=keycloak -d harbor --verbose --clean < harbor.dump\n"})})]})}function h(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>o,x:()=>c});var t=n(6540);const s={},r=t.createContext(s);function o(e){const a=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function c(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:a},e.children)}}}]);